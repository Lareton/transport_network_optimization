{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025f93c1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b75ae8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import math\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "\n",
    "from test_sampler import TestProblem, TestProblem2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93975d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nesterov(x_0, grad, L, mu, K):\n",
    "    x_cur = x_0\n",
    "    y_cur = x_0\n",
    "    x_list = [x_0]\n",
    "    y_list = [x_0]\n",
    "    for i in range(K):\n",
    "        x_upd = y_cur - (1 / L) * (grad(y_cur, L))\n",
    "        y_upd = x_upd + ((np.sqrt(L) - np.sqrt(mu)) / (np.sqrt(L) + np.sqrt(mu))) * (x_upd - x_cur)\n",
    "\n",
    "        x_list.append(x_upd)\n",
    "        y_list.append(y_upd)\n",
    "\n",
    "        x_cur = x_upd\n",
    "        y_cur = y_upd\n",
    "\n",
    "    return x_list, y_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9711c011",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test_problem = TestProblem(gamma=1e5)\n",
    "test_problem = TestProblem2(La=1000, Lb=10)\n",
    "\n",
    "x1_star = - np.linalg.pinv(test_problem.A) @ test_problem.a\n",
    "x2_star = - np.linalg.pinv(test_problem.B) @ test_problem.b\n",
    "# less stable\n",
    "# x_star = np.linalg.solve(test_problem.A, -test_problem.a)\n",
    "# y_star = np.linalg.solve(test_problem.B, -test_problem.b)\n",
    "\n",
    "f_star = test_problem.calc(x1_star, x2_star)[0]\n",
    "def f(x1, x2):\n",
    "    return x1.T @ test_problem.A @ x1 / 2 + test_problem.a @ x1 + x2.T @ test_problem.B @ x2 / 2 + test_problem.b @ x2 \n",
    "\n",
    "f_star, f(x1_star, x2_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba068b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACRCD\n",
    "history = []\n",
    "grad_x_norms = []\n",
    "grad_y_norms = []\n",
    "\n",
    "# y (paper) = q(code_)\n",
    "\n",
    "def ACRCD(x_0, y_0, K):\n",
    "    x_list = [x_0]\n",
    "    y_list = [y_0]\n",
    "\n",
    "    z1_cur = x_0\n",
    "    z2_cur = y_0\n",
    "\n",
    "    q1_cur = x_0\n",
    "    q2_cur = y_0\n",
    "\n",
    "#     L1 = L2 = 200\n",
    "    L1 = test_problem.La\n",
    "    L2 = test_problem.Lb\n",
    "    beta = 1 / 2\n",
    "\n",
    "    n_ = L1 ** beta + L2 ** beta\n",
    "\n",
    "    # q_cur_block (code) = y (paper)\n",
    "    # z_cur_block (code) = z (paper)\n",
    "    for i in tqdm(range(K)):\n",
    "\n",
    "        #####  redefine alpha, tau\n",
    "        alpha = (i + 2) / (2 * n_ ** 2)\n",
    "        tau = 2 / (i + 2)\n",
    "\n",
    "        x1_upd = tau * z1_cur + (1 - tau) * q1_cur\n",
    "        x2_upd = tau * z2_cur + (1 - tau) * q2_cur\n",
    "\n",
    "        # test_problem.x = torch.tensor(x_upd, requires_grad=True)\n",
    "        # test_problem.y = torch.tensor(y_upd, requires_grad=True)\n",
    "        result, grad_x, grad_y = test_problem.calc(x1_upd, x2_upd)\n",
    "        history.append(result.item())\n",
    "        grad_x_norms.append(np.linalg.norm(grad_x))\n",
    "        grad_y_norms.append(np.linalg.norm(grad_y))\n",
    "        #         print(result, torch.norm(grad_x), torch.norm(grad_y))\n",
    "\n",
    "        index_p = np.random.choice([0, 1], p=[L1 ** beta / n_,\n",
    "                                              L2 ** beta / n_])\n",
    "\n",
    "        if index_p == 0:\n",
    "            q1_upd = x1_upd - (1 / L1) * grad_x\n",
    "            q2_upd = q2_cur\n",
    "\n",
    "            z1_upd = z1_cur - (1 / L1) * alpha * n_ * grad_x\n",
    "            z2_upd = z2_cur\n",
    "\n",
    "\n",
    "        if index_p == 1:\n",
    "            q1_upd = q1_cur\n",
    "            q2_upd = x2_upd - (1 / L2) * grad_y\n",
    "\n",
    "            z1_upd = z1_cur\n",
    "            z2_upd = z2_cur - (1 / L2) * alpha * n_ * grad_y\n",
    "\n",
    "        x_list.append(x1_upd)\n",
    "        y_list.append(x2_upd)\n",
    "\n",
    "        z1_cur = z1_upd\n",
    "        z2_cur = z2_upd\n",
    "\n",
    "        q1_cur = q1_upd\n",
    "        q2_cur = q2_upd\n",
    "\n",
    "    return x_list, y_list\n",
    "\n",
    "# x0 = np.random.random(test_problem.na)\n",
    "# y0 = np.random.random(test_problem.nb)\n",
    "\n",
    "x0 = np.zeros(test_problem.na)\n",
    "y0 = np.zeros(test_problem.nb)\n",
    "\n",
    "x_list_ACRCD, y_list_ACRCD = ACRCD(x0, y0, 20000)\n",
    "\n",
    "# plt.plot(torch.log(torch.tensor(history)))\n",
    "\n",
    "plt.plot(torch.tensor(history) - f_star, label='func')\n",
    "plt.plot(torch.tensor(grad_x_norms), label='x grad norm')\n",
    "plt.plot(torch.tensor(grad_y_norms), label='y grad norm')\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b34e23",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "res_x, *gradients_x = test_problem.calc(x_list_ACRCD[-1], y_list_ACRCD[-1])\n",
    "res_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf1755c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "history = []\n",
    "grad_x1_norms = []\n",
    "grad_x2_norms = []\n",
    "\n",
    "# y (paper) = q(code_)\n",
    "count_one, count_two = 0, 0\n",
    "\n",
    "def ACRCD_star(x1_0, x2_0, K):\n",
    "    global count_one, count_two\n",
    "    ADAPTIVE_DELTA = 1e-8\n",
    "\n",
    "    x1_list = [x1_0]\n",
    "    x2_list = [x2_0]\n",
    "\n",
    "    z1 = y1 = x1_0\n",
    "    z2 = y2 = x2_0\n",
    "\n",
    "    L1 = L2 = 5000\n",
    "    beta = 1 / 2\n",
    "\n",
    "    for i in tqdm(range(K)):\n",
    "        tau = 2 / (i + 2)\n",
    "\n",
    "        x1 = tau * z1 + (1 - tau) * y1\n",
    "        x2 = tau * z2 + (1 - tau) * y2\n",
    "\n",
    "#         result, grad_x1, grad_x2 = test_problem.calc(x1, x2)\n",
    "\n",
    "        res_x, *gradients_x = test_problem.calc(x1, x2) # moved out of the inner loop\n",
    "        history.append(res_x.item())\n",
    "        grad_x1_norms.append(np.linalg.norm(gradients_x[0]).item())\n",
    "        grad_x2_norms.append(np.linalg.norm(gradients_x[1]).item())\n",
    "\n",
    "        n_ = L1 ** beta + L2 ** beta\n",
    "        index_p = np.random.choice([0, 1], p=[L1 ** beta / n_,\n",
    "                                              L2 ** beta / n_])\n",
    "        Ls = [L1, L2]\n",
    "        Ls[index_p] /= 2\n",
    "\n",
    "        # ADAPTIVE\n",
    "\n",
    "        inequal_is_true = False\n",
    "        xs = [x1, x2]\n",
    "        sampled_gradient_x = gradients_x[index_p]\n",
    "        # while not inequal_is_true:\n",
    "        for j in range(100):\n",
    "            if index_p == 0:\n",
    "                count_one += 1\n",
    "                y1 = xs[index_p] - 1 / Ls[index_p] * sampled_gradient_x\n",
    "                y2 = x2\n",
    "            else:\n",
    "                count_two += 1\n",
    "                y2 = xs[index_p] - 1 / Ls[index_p] * sampled_gradient_x\n",
    "                y1 = x1\n",
    "                \n",
    "            res_y, *_ = test_problem.calc(y1, y2)\n",
    "                \n",
    "            inequal_is_true = 1 / (2 * Ls[index_p]) * np.linalg.norm(sampled_gradient_x) ** 2 <= res_x - res_y + ADAPTIVE_DELTA\n",
    "#             y_minus_x = ([y1, y2][index_p] - xs[index_p])\n",
    "#             inequal_is_true = (res_y - res_x - gradients_x[index_p] @ y_minus_x \n",
    "#                                 <= Ls[index_p] * (y_minus_x ** 2).sum() / 2 + ADAPTIVE_DELTA)\n",
    "            if inequal_is_true: break\n",
    "            Ls[index_p] *= 2\n",
    "#             if Ls[index_p] > 4 * [test_problem.La, test_problem.Lb][index_p]:\n",
    "#                 print(i, j, index_p, Ls)\n",
    "#                 print(res_y, res_x)\n",
    "\n",
    "        L1, L2 = Ls\n",
    "        n_ = L1 ** beta + L2 ** beta\n",
    "        alpha = (i + 2) / (2 * n_ ** 2)\n",
    "\n",
    "        if index_p == 0:\n",
    "            z1 = z1 - (1 / L1) * alpha * n_ * sampled_gradient_x\n",
    "\n",
    "        if index_p == 1:\n",
    "            z2 = z2 - (1 / L2) * alpha * n_ * sampled_gradient_x\n",
    "\n",
    "        x1_list.append(x1)\n",
    "        x2_list.append(x2)\n",
    "\n",
    "    return x1_list, x2_list, [L1, L2]\n",
    "\n",
    "\n",
    "# np.random.seed(228)\n",
    "x1_list_ACRCD, x2_list_ACRCD, Ls = ACRCD_star(np.random.random(test_problem.na), np.random.random(test_problem.nb), 20000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c903b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.tensor(history) - f_star, label='func')\n",
    "plt.plot(torch.tensor(grad_x1_norms), label='x1 grad norm')\n",
    "plt.plot(torch.tensor(grad_x2_norms), label='x2 grad norm')\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c067d125",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "res_x, *gradients_x = test_problem.calc(x_list_ACRCD[-1], y_list_ACRCD[-1])\n",
    "res_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be8a6a0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# gamma=1e5 [1250.0, 10000.0]\n",
    "# gamma=1e-5 [2500.0, 10000.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af07ffd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
