{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a3c510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import math\n",
    "import copy\n",
    "from dataclasses import dataclass\n",
    "from test_sampler import TestProblem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b1da491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nesterov(x_0, grad, L, mu, K):\n",
    "    x_cur = x_0\n",
    "    y_cur = x_0\n",
    "    x_list = [x_0]\n",
    "    y_list = [x_0]\n",
    "    for i in range(K):\n",
    "        x_upd = y_cur - (1/L)*(grad(y_cur, L))\n",
    "        y_upd = x_upd + ((np.sqrt(L) - np.sqrt(mu))/(np.sqrt(L) + np.sqrt(mu))) * (x_upd - x_cur)\n",
    "\n",
    "\n",
    "        x_list.append(x_upd)\n",
    "        y_list.append(y_upd)\n",
    "\n",
    "        x_cur = x_upd\n",
    "        y_cur = y_upd\n",
    "\n",
    "    return x_list, y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7290b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_quad(x, L):\n",
    "    A = np.array([[L,0],[0,1]])\n",
    "    b = np.array([2,1])\n",
    "    return A@x+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e43dfc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "# @dataclass\n",
    "# class CFG:\n",
    "#     x_0 = np.array([3, 1])\n",
    "#     L = 100\n",
    "#     K = 100000\n",
    "#     mu = 1\n",
    "# \n",
    "#     x_list_nes, y_list_nes = nesterov(x_0, grad_quad, L, mu, K)\n",
    "# \n",
    "#     L_x = 10\n",
    "#     L_y = 1000\n",
    "#     mu_x = 0.1\n",
    "#     mu_y = 0.1\n",
    "#     A = np.array([[L_x, 0, 0, 0], [0, mu_x, 0, 0], [0, 0, L_y, 0], [0, 0, 0, mu_y]])\n",
    "#     b = np.array([2, 1, 3, 1])\n",
    "# \n",
    "#     # x_star = x_list_nes[-1]\n",
    "#     x_star = np.linalg.solve(A, -b)\n",
    "#     # x_0 = np.array([1, 2])\n",
    "#     y_0 = np.array([2, 3])\n",
    "#     n = 4\n",
    "#     x_init = np.array(list(x_0) + list(y_0))\n",
    "# \n",
    "#     d = 1 / 2 * (x_init.T @ A @ x_init + b.T @ x_init)\n",
    "#     theta = np.linalg.norm(x_init - x_star)\n",
    "#     alpha = 0.1\n",
    "#     tau = 1 / (alpha * n * n + 1)\n",
    "#     x_0 = np.array([3, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e93975d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_problem = TestProblem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba068b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n9/tgs43kxj3nz79q8g8t2qzzzw0000gn/T/ipykernel_3164/1319893320.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_problem.x = torch.tensor(x_upd, requires_grad=True)\n",
      "/var/folders/n9/tgs43kxj3nz79q8g8t2qzzzw0000gn/T/ipykernel_3164/1319893320.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_problem.y = torch.tensor(y_upd, requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(641.2473, grad_fn=<AddBackward0>)\n",
      "tensor(-59550.5156, grad_fn=<AddBackward0>)\n",
      "tensor(-752227.2500, grad_fn=<AddBackward0>)\n",
      "tensor(-3758536., grad_fn=<AddBackward0>)\n",
      "tensor(-27034492., grad_fn=<AddBackward0>)\n",
      "tensor(-5.3367e+08, grad_fn=<AddBackward0>)\n",
      "tensor(-1.4492e+10, grad_fn=<AddBackward0>)\n",
      "tensor(-1.2709e+11, grad_fn=<AddBackward0>)\n",
      "tensor(-1.8095e+12, grad_fn=<AddBackward0>)\n",
      "tensor(-4.0944e+13, grad_fn=<AddBackward0>)\n",
      "tensor(-1.3538e+15, grad_fn=<AddBackward0>)\n",
      "tensor(-6.1043e+16, grad_fn=<AddBackward0>)\n",
      "tensor(-7.5820e+17, grad_fn=<AddBackward0>)\n",
      "tensor(-1.4083e+19, grad_fn=<AddBackward0>)\n",
      "tensor(-3.4101e+20, grad_fn=<AddBackward0>)\n",
      "tensor(-1.3362e+22, grad_fn=<AddBackward0>)\n",
      "tensor(-1.6856e+23, grad_fn=<AddBackward0>)\n",
      "tensor(-1.0297e+25, grad_fn=<AddBackward0>)\n",
      "tensor(-2.6134e+26, grad_fn=<AddBackward0>)\n",
      "tensor(-1.4309e+28, grad_fn=<AddBackward0>)\n",
      "tensor(-4.3478e+29, grad_fn=<AddBackward0>)\n",
      "tensor(-2.3880e+31, grad_fn=<AddBackward0>)\n",
      "tensor(-1.0196e+33, grad_fn=<AddBackward0>)\n",
      "tensor(-1.2730e+34, grad_fn=<AddBackward0>)\n",
      "tensor(-2.5344e+35, grad_fn=<AddBackward0>)\n",
      "tensor(-7.2201e+36, grad_fn=<AddBackward0>)\n",
      "tensor(-inf, grad_fn=<AddBackward0>)\n",
      "tensor(-inf, grad_fn=<AddBackward0>)\n",
      "tensor(-inf, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# ACRCD\n",
    "\n",
    "\n",
    "def ACRCD(x_0, y_0, K):\n",
    "    x_list = [x_0]\n",
    "    y_list = [y_0]\n",
    "\n",
    "    x_cur = x_0\n",
    "    y_cur = y_0\n",
    "\n",
    "    z_cur_x = x_0\n",
    "    z_cur_y = y_0\n",
    "\n",
    "    q_cur_x = x_0\n",
    "    q_cur_y = y_0\n",
    "    \n",
    "    L_x, L_y = 10, 10\n",
    "    beta = 2\n",
    "\n",
    "\n",
    "    n_ =  L_x ** beta + L_y ** beta\n",
    "    \n",
    "    # q_cur (code) = y (paper)\n",
    "    for i in range(K):\n",
    "        \n",
    "        #####  redefine alpha, tau\n",
    "        alpha = (i + 2) / (2 * n_ ** 2)\n",
    "        tau = 2 / (i + 2)\n",
    "        \n",
    "        x_upd = tau*z_cur_x+(1-tau)*q_cur_x\n",
    "        y_upd = tau*z_cur_y+(1-tau)*q_cur_y\n",
    "        \n",
    "        test_problem.x = torch.tensor(x_upd, requires_grad=True)\n",
    "        test_problem.y = torch.tensor(y_upd, requires_grad=True)\n",
    "        result, grad_x, grad_y = test_problem.calc()\n",
    "        print(result)\n",
    "\n",
    "        \n",
    "        index_p = np.random.choice([0,1],p=[L_x ** beta / n_, \n",
    "                                            L_y ** beta / n_])\n",
    "        \n",
    "        if index_p == 0:\n",
    "            q_upd_x = x_upd - (1/L_x)*grad_x\n",
    "            q_upd_y = q_cur_y\n",
    "\n",
    "        if index_p == 1:\n",
    "            q_upd_y = y_upd - (1/L_y)*grad_y\n",
    "            q_upd_x = q_cur_x\n",
    "\n",
    "        if index_p == 0:\n",
    "            z_upd_x = z_cur_x - (1/L_x)*alpha*n_*grad_x\n",
    "            z_upd_y = z_cur_y\n",
    "\n",
    "        if index_p == 1:\n",
    "            z_upd_y = z_cur_y - (1/L_y)*alpha*n_*grad_y\n",
    "            z_upd_x = z_cur_x\n",
    "\n",
    "\n",
    "\n",
    "        x_list.append(x_upd)\n",
    "        y_list.append(y_upd)\n",
    "\n",
    "        x_cur = x_upd\n",
    "        y_cur = y_upd\n",
    "\n",
    "        z_cur_x = z_upd_x\n",
    "        z_cur_y = z_upd_y\n",
    "\n",
    "        q_cur_x = q_upd_x\n",
    "        q_cur_y = q_upd_y\n",
    "\n",
    "\n",
    "    return x_list, y_list\n",
    "\n",
    "\n",
    "x_list_ACRCD, y_list_ACRCD = ACRCD(torch.rand(1000), torch.rand(2000, requires_grad=True), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7dd2ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8786c0da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
